# 机器学习工程实践流程
**1. 给定一个任务，一般处理流程**
- 明确问题与指标  
  - 分类：准确率 / F1 / AUC；回归：MSE / MAE；聚类：轮廓系数 / NMI 等。  
  - 确认约束：时延、资源、可解释性、上线环境。
- 数据相关  
  - 明确输入输出（特征、标签） 
  - 划分训练 / 验证 / 测试集（时间序列用时间切分，其他可随机或分层采样）。  
  - 数据预处理
    - 缺失值异常值处理、归一化 / 标准化、类别特征编码、处理类别不平衡
- 特征工程（见下一节）  
- 模型选择与训练（见“神经网络结构和算法选择”节）  
- 评估与迭代  
  - 在验证集/交叉验证上选模型和超参；最后只在测试集上评估一次.  
  - 通过学习曲线、错误分析决定是“加数据/调特征/换模型”。
---
**2. 数据集处理**
- 明确输入输出（特征、标签） 
- 选择数据  
  - 覆盖业务场景：不同时间段、人群、设备、环境。  
  - 尽量保持“训练分布 ≈ 上线分布”，避免历史老数据过多导致分布偏移。  
  - 剔除明显标注错误或严重异常样本（必要时单独建立“异常检测”任务）。
- 采样策略  
  - 非平衡分类：分层采样，保持各类别比例稳定。  
  - 数据量极大时：先采一小部分做原型和特征验证。
    - 什么是原型和特征验证？
      - 原型验证：用简单模型（LR/小树/小 NN）验证特征有效性和任务难度。  
      - 特征验证：用简单统计量（相关系数、卡方等）验证特征与标签的关联度。
- 数据清洗与预处理
  - 缺失值处理：删除严重缺失特征，轻度缺失用均值/众数/插值/特殊值填充。  
  - 异常值处理：基于领域知识设定阈值，或用统计方法（如 z-score、IQR）检测并处理。
  - 归一化 / 标准化（特别是线性模型、NN、距离类算法）。  
  - 类别特征编码：one-hot / target encoding / embedding（深度模型）。  
  - 处理类别不平衡：重采样（上采少数、下采多数）、类别权重、调整决策阈值。
- 划分训练 / 验证 / 测试集
  - （时间序列用时间切分，其他可随机或分层采样）。
---
**3. 怎样选择特征**
- 业务驱动优先  
  - 先列出你“认为和标签强相关的信号”，按领域知识构造。  
  - 避免明显泄漏特征（如用“是否已退货”预测“未来是否退货”）。
- 过滤式  
  - 单特征 vs 标签的相关系数、互信息、卡方、方差等，做初筛。  
  - 删除几乎常数、极端稀有取值、与其他特征几乎完全相关的特征。
- 包裹式  
  - 用一个基线模型（如树模型、LR）做递归特征消除（RFE）或前向/后向选择。 
    - 基线模型和真实模型不必完全一样，但要有一定代表性。 
- 嵌入式 
  - L1 正则的线性模型：保留非零权重特征。  
  - 树模型：按 split 频次 / 信息增益排序特征重要性。  
  - 深度学习：使用 attention / embedding 等分析重要性，但更偏后分析。
- 实践建议  
  - 先用过滤式 + 嵌入式做粗筛，再在可控维度下用包裹式精调。  
  - 特征数量和样本数要平衡：结构化表格里，特征过多、样本有限时优先删冗余。
---
**4. 神经网络结构 & 其他算法选择**

- 总原则：从简单到复杂，优先“成熟 baseline”，复杂模型只在有明显收益时使用。
- 表格型结构化数据  
  - 首选：LR + 树模型（GBDT / XGBoost / LightGBM / 随机森林）。  
  - 深度网络（MLP）一般只有在数据量特别大、特征交叉非常复杂时才明显胜出。
- 文本  
  - 简单场景：TF-IDF + LR / SVM。  
  - 复杂语义：预训练模型（BERT 系列）、轻量化 fine-tune（LoRA、prefix tuning）。
- 图像 / 语音 / 时序信号  
  - 图像：CNN / ViT（优先用成熟 backbone，如 ResNet、EfficientNet）。  
  - 一维时序：1D-CNN、RNN/LSTM/GRU、Transformer（如 TST、TimeSeriesTransformer）。
- 神经网络结构怎么定（经验法则）  
  - 先选成熟架构和规模（参考论文/开源实现），不要凭感觉“拍脑袋设计网络”。  
  - 样本少：先用小网络、强正则（L2、dropout、BN、early stopping）。  
  - 发现欠拟合（训练/验证误差都高）：再逐步加宽/加深或换更强框架。  
  - 诸如层数、每层宽度、激活函数、归一化类型，用“少量候选 + 超参搜索”而不是穷举。
      - 先根据经验选出几个合理的层数/宽度范围（如 3-5 层，每层 64-256 单元），然后用超参搜索（见后节）找最优组合，而不是从 1 层到 20 层、每层从 16 到 1024 单元都试一遍。
---
**5. 如何快速分析任务难度**

- 直观可分性  
  - 人工看：随机抽样，用肉眼能否大致判断类别 / 回归趋势。  
  - 可视化：用 PCA / t-SNE / UMAP 降到 2D/3D，看看不同类别是否有明显分界。
- 简单模型 baseline  
  - 先训一个线性模型（LR/线性回归）和一个简单树模型，对比指标。  
  - 如果简单模型就有很好效果，说明任务相对“容易”；如果各种模型都很糟，任务本身可能接近“噪声”或特征不足。
- 学习曲线  
  - 固定模型，看训练/验证指标随样本数变化曲线：  
    - 验证指标随样本增加持续、明显上升 → 数据更多仍有收益，暂不必过分堆复杂模型。  
    - 很早就饱和 → 换特征/模型比加数据更关键。
- 标签噪声  
  - 抽样检查标签一致性；多标注员一致性分析；用“预测最难的样本”做人工复核。
---
**6. 如何判断样本数是否足够**

- 理论上难有精确公式，实战靠“学习曲线 + 偏差/方差分析”：
  - 高方差：训练误差低、验证误差高 → 模型在现有数据上过拟合 → 通常“数据不够或模型太复杂”。  
    - 看学习曲线：如果增加样本能显著降低验证误差 → 数据目前不够。  
  - 高偏差：训练和验证误差都高 → 换更强模型/更好特征，而不是一味加数据。
- 经验原则  
  - 经典浅层模型：样本数至少是“有效特征数”的 5–10 倍以上更靠谱。  
  - 深度网络：参数远多于样本数时，高度依赖强正则与数据增强，多数场景下要“十万级以上”才比较稳（视任务而定）。
- 监控上线表现  
  - 如果线上表现与离线验证差很多，且方差型问题明显（偶尔极差），也可能意味着数据覆盖不够。
---
**7. 超参数搜索的一般流程**

- 第一步：确定要调的超参 & 合理范围  
  - 优先级最高：学习率、正则强度（L2/L1）、模型容量（树深度/网络层数和宽度）、batch size、dropout 比例等。  
  - 范围尽量用数量级：如学习率 [1e-4, 1e-1]，正则 [1e-6, 1e-2]。
- 第二步：选择搜索策略  
  - 小模型、小空间：grid search（网格搜索）。  
  - 稍大空间：random search，通常比网格更高效。  
  - 资源有限 + 空间大：贝叶斯优化、Hyperband/BOHB 等（很多框架已集成）。
    - 贝叶斯优化搜索超参是什么 原理
      - 基于已有的超参-性能数据，构建一个代理模型（如高斯过程），预测不同超参组合的性能分布；
      - 通过优化采集函数（如期望改进、概率改进）选择下一个要评估的超参组合，平衡探索和利用；
      - 迭代进行超参评估和代理模型更新，逐步逼近最优超参组合。 
    - Hyperband 通过“早停”机制，快速淘汰表现不佳的超参数组合，将更多资源集中在有潜力的组合上；
      - 假设你有 100 个训练轮次的资源，要从 100 组超参中选最优：
      - 步骤 1：资源分层 + 随机采样
      - 步骤 2：早停淘汰，资源倾斜
      给所有 100 组超参只分配 1 轮资源（训练 1 轮），评估性能后淘汰最差的 2/3，剩下 33 组；
      给这 33 组分配 3 轮资源，评估后再淘汰 2/3，剩下 11 组；
    - BOHB 结合了贝叶斯优化和 Hyperband 的优点，利用贝叶斯优化指导资源分配，提高搜索效率和效果。
- 第三步：评估策略  
  - 分类：考虑使用 K 折交叉验证 + 目标指标（F1/AUC等）。  
  - 时间序列：用 rolling/expanding window 代替普通交叉验证。  
  - **每次训练设置早停，避免在明显差的超参上浪费训练时间**。
- 第四步：粗调 → 细调  
  - 先用较粗的搜索（范围大、步长大、迭代少）找到“可用区间”；  
  - 再在较小区间内（如学习率在 [1e-3, 3e-3]）做精细搜索。
- 第五步：确定最终模型  
  - 用“训练集 + 验证集”在选出的最佳超参下重新训练一次；  
  - 只用测试集做一次最终评估，不再反复用测试集调参。
---